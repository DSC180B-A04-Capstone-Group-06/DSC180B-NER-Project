{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_condi(string):\n",
    "    if \".com\" in string:\n",
    "        return False\n",
    "    if \".edu\" in string:\n",
    "        return False\n",
    "    if \"@\" in string:\n",
    "        return False\n",
    "    if 'Host'in string:\n",
    "        return False\n",
    "    if \".gov\" in string:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def clean_text(string):\n",
    "    string = \" \".join([i for i in string.split() if regex_condi(i)])\n",
    "    string = re.sub(r\"Re:\",\"\", string)\n",
    "    string = re.sub(r\"Reply-To:\",\"\", string)\n",
    "    toreturn = string.strip()\n",
    "    return toreturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "newsgroups_train_X,newsgroups_train_y = newsgroups_train.data, newsgroups_train.target\n",
    "newsgroups_val_X, newsgroups_test_X, newsgroups_val_y, newsgroups_test_y = train_test_split(newsgroups_test.data, newsgroups_test.target, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "# Clean train \n",
    "newsgroups_train_X = [clean_text(i) for i in newsgroups_train_X]\n",
    "newsgroups_val_X = [clean_text(i) for i in newsgroups_val_X]\n",
    "newsgroups_test_X =  [clean_text(i) for i in newsgroups_test_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoG_model(X,y, clf = 'Logistic', vocab = None):\n",
    "    \"\"\"\n",
    "    This function take in training data as X, y. \n",
    "    Then the data will be processed with BagOfWord, then feed into the Logistic / SGD Classifier.\n",
    "\n",
    "    Return:\n",
    "        pipe: The fitted Logistic Classifier.\n",
    "    \"\"\"\n",
    "    if vocab == None:\n",
    "        if clf == 'Logistic':\n",
    "            pipe = Pipeline([\n",
    "               ('BagOfWord', CountVectorizer()),\n",
    "               ('clasiffier', LogisticRegression())\n",
    "               ])\n",
    "        if clf == 'SVM':\n",
    "            pipe = Pipeline([\n",
    "               ('BagOfWord', CountVectorizer()),\n",
    "               ('clasiffier', SGDClassifier())\n",
    "               ])\n",
    "    else:\n",
    "        if clf == 'Logistic':\n",
    "            pipe = Pipeline([\n",
    "               ('BagOfWord', CountVectorizer(vocabulary =vocab)),\n",
    "               ('clasiffier', LogisticRegression())\n",
    "               ])\n",
    "        if clf == 'SVM':\n",
    "            pipe = Pipeline([\n",
    "               ('BagOfWord', CountVectorizer(vocabulary =vocab)),\n",
    "               ('clasiffier', SGDClassifier())\n",
    "               ])\n",
    "    pipe.fit(X, y)\n",
    "    return pipe\n",
    "\n",
    "def Tfidf_model(X,y, clf = 'Logistic', vocab = None):\n",
    "\n",
    "    \"\"\"\n",
    "    This function take in training data as X, y. \n",
    "    Then the data will be processed with BagOfWord and Tf-Idf, then feed into the Logistic Classifier.\n",
    "\n",
    "    Return:\n",
    "        pipe: The fitted Logistic Classifier.\n",
    "    \"\"\"\n",
    "    if vocab == None:\n",
    "        if clf == 'Logistic':\n",
    "            pipe = Pipeline([\n",
    "                ('BagOfWord', CountVectorizer()),\n",
    "                ('TfIdf',TfidfTransformer()),\n",
    "                ('clasiffier', LogisticRegression())\n",
    "                ])\n",
    "        if clf == 'SVM':\n",
    "            pipe = Pipeline([\n",
    "                ('BagOfWord', CountVectorizer()),\n",
    "                ('TfIdf',TfidfTransformer()),\n",
    "                ('clasiffier', SGDClassifier())\n",
    "                ])\n",
    "    else:\n",
    "        if clf == 'Logistic':\n",
    "            pipe = Pipeline([\n",
    "                ('BagOfWord', CountVectorizer(vocabulary =vocab)),\n",
    "                ('TfIdf',TfidfTransformer()),\n",
    "                ('clasiffier', LogisticRegression())\n",
    "                ])\n",
    "        if clf == 'SVM':\n",
    "            pipe = Pipeline([\n",
    "                ('BagOfWord', CountVectorizer(vocabulary =vocab)),\n",
    "                ('TfIdf',TfidfTransformer()),\n",
    "                ('clasiffier', SGDClassifier())\n",
    "                ])\n",
    "    pipe.fit(X, y)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yang Li\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7774827403080191"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_Count_clf = BoG_model(newsgroups_train_X, newsgroups_train_y)\n",
    "predicted = Log_Count_clf.predict(newsgroups_val_X)\n",
    "np.mean(predicted == newsgroups_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8266064790228359"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Log_TFIDF_clf = Tfidf_model(newsgroups_train_X, newsgroups_train_y)\n",
    "predicted = Log_TFIDF_clf.predict(newsgroups_val_X)\n",
    "np.mean(predicted == newsgroups_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7525225703664365"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_Count_clf = BoG_model(newsgroups_train_X, newsgroups_train_y, clf = 'SVM')\n",
    "predicted = SVM_Count_clf.predict(newsgroups_val_X)\n",
    "np.mean(predicted == newsgroups_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8454593733404142"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_TFIDF_clf = Tfidf_model(newsgroups_train_X, newsgroups_train_y, clf = 'SVM')\n",
    "SVM_TFIDF_clf.fit(newsgroups_train_X, newsgroups_train_y)\n",
    "predicted = SVM_TFIDF_clf.predict(newsgroups_val_X)\n",
    "np.mean(predicted == newsgroups_val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/temp',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        From: lerxst@wam.umd.edu (where's my thing)\\nS...\n",
       "1        From: guykuo@carson.u.washington.edu (Guy Kuo)...\n",
       "2        From: twillis@ec.ecn.purdue.edu (Thomas E Will...\n",
       "3        From: jgreen@amber (Joe Green)\\nSubject: Re: W...\n",
       "4        From: jcm@head-cfa.harvard.edu (Jonathan McDow...\n",
       "                               ...                        \n",
       "11309    From: jim.zisfein@factory.com (Jim Zisfein) \\n...\n",
       "11310    From: ebodin@pearl.tufts.edu\\nSubject: Screen ...\n",
       "11311    From: westes@netcom.com (Will Estes)\\nSubject:...\n",
       "11312    From: steve@hcrlgw (Steven Collins)\\nSubject: ...\n",
       "11313    From: gunning@cco.caltech.edu (Kevin J. Gunnin...\n",
       "Name: data, Length: 11314, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame.from_dict(newsgroups_train,'index').T\n",
    "news_df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/temp/20news.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(news_df.data.apply(lambda x: clean_text(x)+ '.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.988864</td>\n",
       "      <td>george bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987358</td>\n",
       "      <td>red sox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.986398</td>\n",
       "      <td>attorney general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985885</td>\n",
       "      <td>gulf war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.985655</td>\n",
       "      <td>silicon graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12030</th>\n",
       "      <td>0.003707</td>\n",
       "      <td>not exactly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12031</th>\n",
       "      <td>0.003279</td>\n",
       "      <td>can't do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12032</th>\n",
       "      <td>0.003142</td>\n",
       "      <td>r +</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12033</th>\n",
       "      <td>0.003109</td>\n",
       "      <td>probably not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12034</th>\n",
       "      <td>0.002878</td>\n",
       "      <td>if you've</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12035 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              p            phrase\n",
       "0      0.988864       george bush\n",
       "1      0.987358           red sox\n",
       "2      0.986398  attorney general\n",
       "3      0.985885          gulf war\n",
       "4      0.985655  silicon graphics\n",
       "...         ...               ...\n",
       "12030  0.003707       not exactly\n",
       "12031  0.003279          can't do\n",
       "12032  0.003142               r +\n",
       "12033  0.003109      probably not\n",
       "12034  0.002878         if you've\n",
       "\n",
       "[12035 rows x 2 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/temp/AutoPhrase.txt',error_bad_lines=False, delimiter= '\\t',names = ['p','phrase'])\n",
    "select = df[df.p >= 0.5]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(vocabulary = select.phrase,stop_words = 'english')\n",
    "count_vect = count_vect.fit_transform(newsgroups_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
