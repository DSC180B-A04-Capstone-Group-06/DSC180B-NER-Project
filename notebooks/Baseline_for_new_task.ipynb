{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = ['text','type','summary','type_code']\n",
    "test_df = test_df.reset_index(drop = True)\n",
    "test_df.head()\n",
    "test_df.to_csv('../data/temp/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"../data/raw/BBC News Summary/News Articles/\"\n",
    "entries = os.listdir(data_folder)\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "for i in entries:\n",
    "    temp = []\n",
    "    folder_path = data_folder + i +'/'\n",
    "    file_lst = os.listdir(folder_path)\n",
    "    for j in file_lst:\n",
    "        if j != '.ipynb_checkpoints':\n",
    "            with open(folder_path +j, 'r', errors='ignore') as file:\n",
    "                temp.append(file.read().replace('\\n', ''))\n",
    "    all_data[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_folder = \"../data/raw/BBC News Summary/Summaries/\"\n",
    "summary_entries = os.listdir(data_folder)\n",
    "all_sum = {}\n",
    "for i in entries:\n",
    "    temp = []\n",
    "    folder_path = summary_folder + i +'/'\n",
    "    file_lst = os.listdir(folder_path)\n",
    "    for j in file_lst:\n",
    "        if j != '.ipynb_checkpoints':\n",
    "            with open(folder_path +j, 'r', errors='ignore') as file:\n",
    "                temp.append(file.read().replace('\\n', ''))\n",
    "    all_sum[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for i in np.arange(len(entries)):\n",
    "    if i == 0:\n",
    "        total_df = pd.DataFrame.from_dict(all_data['business'])\n",
    "        total_df['type'] = 'business'\n",
    "        total_df['summary'] = all_sum['business']\n",
    "        total_df['type_code'] = i+1\n",
    "        \n",
    "        \n",
    "        index = np.random.choice(total_df.shape[0],10)\n",
    "        test_df = total_df.loc[index]\n",
    "    else:\n",
    "        temp_df = pd.DataFrame.from_dict(all_data[entries[i]])\n",
    "        temp_df['type'] = entries[i]\n",
    "        temp_df['summary'] = all_sum[entries[i]]\n",
    "        temp_df['type_code'] = i+1\n",
    "        total_df =pd.concat([total_df, temp_df], axis=0)\n",
    "        \n",
    "        index = np.random.choice(temp_df.shape[0], 10)\n",
    "        temp_test_df = temp_df.loc[index]\n",
    "        test_df =pd.concat([test_df,temp_test_df] , axis=0) \n",
    "        \n",
    "total_df.columns = ['text','type','summary','type_code']\n",
    "total_df = total_df.reset_index(drop = True)\n",
    "total_df.to_csv('../data/temp/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/raw/BBC News Summary/News Articles/\"\n",
    "entries = os.listdir('../data/raw/BBC News Summary/News Articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"../data/raw/BBC News Summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame.from_dict(newsgroups_train,'index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_condi(string):\n",
    "    if \".com\" in string:\n",
    "        return False\n",
    "    if \".edu\" in string:\n",
    "        return False\n",
    "    if \"@\" in string:\n",
    "        return False\n",
    "    if 'Host'in string:\n",
    "        return False\n",
    "    if \".gov\" in string:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_text(string):\n",
    "    string = \" \".join([i for i in string.split() if regex_condi(i)])\n",
    "    string = re.sub(r\"Re:\",\"\", string)\n",
    "    string = re.sub(r\"Reply-To:\",\"\", string)\n",
    "\n",
    "    string_lst = string.split(': ')\n",
    "    \n",
    "    \n",
    "    toreturn = \"\"\n",
    "    for i in np.arange(len(string_lst) - 1):\n",
    "        if \"Subject\" in string_lst[i]:\n",
    "            temp = string_lst[i+1].split(' ')\n",
    "            toreturn += \" \" + ' '.join(temp[:-1])\n",
    "        if \"Keywords\" in string_lst[i]:\n",
    "            temp = string_lst[i+1].split(' ')\n",
    "            toreturn += \" \" + ' '.join(temp[:-1])\n",
    "        if \"Organization\" in string_lst[i]:\n",
    "            temp = string_lst[i+1].split(' ')\n",
    "            toreturn += \" \" + ' '.join(temp[:-1])\n",
    "            \n",
    "        if \"Lines\" in string_lst[i]:\n",
    "            temp = \"\"\n",
    "            for j in range(i+1,len(string_lst)):\n",
    "                temp += string_lst[j]\n",
    "            toreturn += temp\n",
    "            break\n",
    "\n",
    "    toreturn = re.sub(r\"\\'\", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"\\>\", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"\\:\", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"^[0-9]+ \", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"\\/\", ' ',toreturn)\n",
    "    toreturn = re.sub(r\"\\-{2,}\", ' ',toreturn)\n",
    "    toreturn = re.sub(r\"\\s+\", ' ',toreturn)\n",
    "    toreturn = toreturn.strip()\n",
    "    return toreturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'From: mathew Subject: Re: <Political Atheists? Organization: Mantis Consultants, Cambridge. UK. X-Newsreader: rusnews v1.01 Lines: 22 (Keith M. Ryan) writes: > ( I am almost sure that Zyklon-B is immediate and painless method of > death. If not, insert soem other form. ) > > And, ethnic and minority groups have been killed, mutilated and > exterminated through out history, so I guess it was not unusual. > > So, you would agree that the holocost would be allowed under the US > Constitution? [ in so far, the punishment. I doubt they recieved what would > be considered a \"fair\" trial by US standards. Don\\'t be so sure. Look what happened to Japanese citizens in the US during World War II. If you\\'re prepared to say \"Let\\'s round these people up and stick them in a concentration camp without trial\", it\\'s only a short step to gassing them without trial. After all, it seems that the Nazis originally only intended to imprison the Jews; the Final Solution was dreamt up partly because they couldn\\'t afford to run the camps because of the devastation caused by Goering\\'s Total War. Those who weren\\'t gassed generally died of malnutrition or disease. mathew'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([i for i in news_df.data[15].split() if regex_condi(i)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From',\n",
       " '(David B. Mckissock) Subject',\n",
       " 'Re',\n",
       " 'Space Station Redesign, JSC Alternative #4 Organization',\n",
       " 'NASA Lewis Research Center / Cleveland, Ohio Lines',\n",
       " '102 Distribution',\n",
       " 'world tm0006.lerc.nasa.gov News-Software',\n",
       " 'VAX/VMS VNEWS 1.41 In article writes... {Description of \"External Tank\" option for SSF redesign deleted} >Mark proposed this design at Joe Shea\\'s committee in Crystal City, >and he reports that he was warmly received. However, the rumors >I hear say that a design based on a wingless Space Shuttle Orbiter >seems more likely. Yo Ken, let\\'s keep on-top of things! Both the \"External Tank\" and \"Wingless Orbiter\" options have been deleted from the SSF redesign options list. Today\\'s (4/23) edition of the New York Times reports that O\\'Connor told the panel that some redesign proposals have been dropped, such as using the \"giant external fuel tanks used in launching space shuttles,\" and building a \"station around an existing space shuttle with its wings and tail removed.\" Currently, there are three options being considered, as presented to the advisory panel meeting yesterday (and as reported in today\\'s Times). Option \"A\" - Low Cost Modular Approach This option is being studied by a team from MSFC. {As an aside, there are SSF redesign teams at MSFC, JSC, and LaRC supporting the SRT (Station Redesign Team) in Crystal City. Both LeRC and Reston folks are also on-site at these locations, helping the respective teams with their redesign activities.} Key features of this option are',\n",
       " '- Uses \"Bus-1\", a modular bus developed by Lockheed that\\'s qualified for STS and ELV\\'s. The bus provides propulsion, GN&C Communications, & Data Management. Lockheed developed this for the Air Force. - A \"Power Station Capability\" is obtained in 3 Shuttle Flights. SSF Solar arrays are used to provide 20 kW of power. The vehicle flies in an \"arrow mode\" to optimize the microgravity environment. Shuttle/Spacelab missions would utilize the vehilce as a power source for 30 day missions. - Human tended capability (as opposed to the old SSF sexist term of man-tended capability) is achieved by the addition of the US Common module. This is a modified version of the existing SSF Lab module (docking ports are added for the International Partners\\' labs, taking the place of the nodes on SSF). The Shuttle can be docked to the station for 60 day missions. The Orbiter would provide crew habitability & EVA capability. - International Human Tended. Add the NASDA & ESA modules, and add another 20 kW of power - Permanent Human Presence Capability. Add a 3rd power module, the U.S. habitation module, and an ACRV (Assured Crew Return Vehicle). Option \"B\" - Space Station Freedom Derived The Option \"B\" team is based at LaRC, and is lead by Mike Griffin. This option looks alot like the existing SSF design, which we have all come to know and love :) This option assumes a lightweight external tank is available for use on all SSF assembly flights (so does option \"A\"). Also, the number of flights is computed for a 51.6 inclination orbit, for both options \"A\" and \"B\". The build-up occurs in six phases',\n",
       " '- Initial Research Capability reached after 3 flights. Power is transferred from the vehicle to the Orbiter/Spacelab, when it visits. - Man-Tended Capability (Griffin has not yet adopted non-sexist language) is achieved after 8 flights. The U.S. Lab is deployed, and 1 solar power module provides 20 kW of power. - Permanent Human Presence Capability occurs after 10 flights, by keeping one Orbiter on-orbit to use as an ACRV (so sometimes there would be two Orbiters on-orbit - the ACRV, and the second one that comes up for Logistics & Re-supply). - A \"Two Fault Tolerance Capability\" is achieved after 14 flights, with the addition of a 2nd power module, another thermal control system radiator, and more propulsion modules. - After 20 flights, the Internationals are on-board. More power, the Habitation module, and an ACRV are added to finish the assembly in 24 flights. Most of the systems currently on SSF are used as-is in this option, with the exception of the data management system, which has major changes. Option C - Single Core Launch Station. This is the JSC lead option. Basically, you take a 23 ft diameter cylinder that\\'s 92 ft long, slap 3 Space Shuttle Main Engines on the backside, put a nose cone on the top, attached it to a regular shuttle external tank and a regular set of solid rocket motors, and launch the can. Some key features are',\n",
       " '- Complete end-to-end ground integration and checkout - 4 tangentially mounted fixed solar panels - body mounted radiators (which adds protection against micrometeroid & orbital debris) - 2 centerline docking ports (one on each end) - 7 berthing ports - a single pressurized volume, approximately 26,000 cubic feet (twice the volume of skylab). - 7 floors, center passageway between floors - 10 kW of housekeeping power - graceful degradation with failures (8 power channels, 4 thermal loops, dual environmental control & life support system) - increased crew time for utilization - 1 micro-g thru out the core module']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \" \".join([i for i in news_df.data[13].split() if regex_condi(i)]) \n",
    "string.split(': ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Question for those with popular morality Camtec Electronics (Ericsson), Leicester, England77 bangkok In article (James Owens) writes In a previous article, (David Bold) says I dont mean to be rude, but I think that youve got hold of the wrong end of a different stick... David I had a look at your posting again and I see what you mean! I was so intent on explaining how Jung thought we could be more moral than God that I overlooked your main line of thought. You seem to be saying that, God being unknowable, His morality is unknowable. Yep, thats pretty much it. Im not a Jew but I understand that this is the Jewish way of thinking. However, the Jews believe that the Covenant between YHWH and the Patriarchs (Abraham and Moses, in this case) establishes a Moral Code to follow for mankind. Even the Jews could not decide where the boundaries fall, though. As I understand it, the Sadducees believed that the Torah was all that was required, whereas the Pharisees (the ancestors of modern Judaism) believed that the Torah was available for interpretation to lead to an understanding of the required Morality in all its nuances (-Talmud). The essence of all of this is that Biblical Morality is an interface between Man and YHWH (for a Jew or Christian) and does not necessarily indicate anything about YHWH outside of that relationship (although one can speculate). The first thing that comes to mind is that man is supposed to be created in His image, so there is an argument that we are committed to whatever moral code He follows as part of trying to live up to that image. If we are supposed to live by Christs example, you would be hard pressed to argue that God is a \"do what I say, not what I do\" kind of guy. The trouble with all of this is that we dont really know what the \"created in His image\" means. Ive heard a number of different opinions on this and have still not come to any conclusion. This rather upsets the Apple Cart if one wants to base a Life Script on this shaky foundation (to mix metaphors unashamedly!) As to living by Christs example, we know very little about Jesus as a person. We only have his recorded utterances in a set of narratives by his followers, and some very small references from comtemporary historians. Revelation aside, one can only \"know\" Christ second-hand or worse. This is not an attempt to debunk Christianity (although it may seem that way initially), the point I`m trying to make is that we only really have the Bible to interpret, and that interpretation is by humanity. I guess this is where Faith or Relevation comes in with all its inherent subjectiveness. Metaphysically, if there are multiple moral codes then there is no Absolute moral code, and I think this is theologically questionable. No. There may be an absolute moral code. There are undoubtably multiple moral codes. The multiple moral codes may be founded in the absolute moral code. As an example, a parent may tell a child never to swear, and the child may assume that the parent never swears simply because the parent has told the child that it is \"wrong\". Now, the parent may swear like a trooper in the pub or bar (where there are no children). The \"wrongness\" here is if the child disobeys the parent. The parent may feel that it is \"inappropriate\" to swear in front of children but may be quite happy to swear in front of animals. The analogy does not quite hold water because the child knows that he is of the same type as the parent (and may be a parent later in life) but you get the gist of it? Incidentally, the young child considers the directive as absolute until he gets older (see Piaget) and learns a morality of his own. David. On religion\"Oh, where is the sea?\", the fishes cried, As they swam its clearness through.'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(news_df.data[11]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/temp',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/temp/text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(news_df.data.apply(lambda x: clean_text(x)+ '.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = ' '.join([f'{param}={value}' for param, value in json.load(open('../config/autoPhrase.json')).items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'cd ../AutoPhrase/ && {para} ./auto_phrase.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.data = news_df.data.apply(lambda x: clean_text(x)+ '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/raw/20_newsgroups/\"\n",
    "entries = os.listdir(data_folder)\n",
    "all_data = {}\n",
    "for i in entries:\n",
    "    temp = []\n",
    "    folder_path = data_folder + i +'/'\n",
    "    file_lst = os.listdir(folder_path)\n",
    "    for j in file_lst:\n",
    "        if j != '.ipynb_checkpoints':\n",
    "            with open(folder_path +j, 'r', errors='ignore') as file:\n",
    "                temp.append(file.read().replace('\\n', ''))\n",
    "    all_data[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for i in np.arange(len(entries)):\n",
    "    if i == 0:\n",
    "        total_df = pd.DataFrame.from_dict(all_data['alt.atheism'])\n",
    "        total_df['type'] = 'alt.atheism'\n",
    "        total_df['type_code'] = i+1\n",
    "        \n",
    "        \n",
    "        index = np.random.choice(total_df.shape[0],10)\n",
    "        test_df = total_df.loc[index]\n",
    "    else:\n",
    "        temp_df = pd.DataFrame.from_dict(all_data[entries[i]])\n",
    "        temp_df['type'] = entries[i]\n",
    "        temp_df['type_code'] = i+1\n",
    "        total_df =pd.concat([total_df, temp_df], axis=0)\n",
    "        \n",
    "        index = np.random.choice(temp_df.shape[0], 10)\n",
    "        temp_test_df = temp_df.loc[index]\n",
    "        test_df =pd.concat([test_df,temp_test_df] , axis=0) \n",
    "        \n",
    "\n",
    "total_df = total_df.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('../data/temp/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"../data/temp/all_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1c1b95ae4f6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "X = df.text\n",
    "Y = df.type_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c223d9c06c0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val,X_test, y_val,y_test = train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "BoG = CountVectorizer().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bog_X_train = BoG.transform(X_train)\n",
    "Bog_X_val = BoG.transform(X_val)\n",
    "Bog_X_test = BoG.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-8c9025357ac9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBog_X_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(Bog_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(Bog_X_train)\n",
    "np.mean(predicted == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952808988764045"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(Bog_X_val)\n",
    "np.mean(predicted == y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9640449438202248"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(Bog_X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-931765772341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfTransformer().fit(Bog_X_train)\n",
    "tfidf_X = tfidf.transform(Bog_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=500)\n",
    "clf.fit(tfidf_X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5325842696629214"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(Bog_X_train)\n",
    "np.mean(predicted == y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5123595505617977"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(Bog_X_val)\n",
    "np.mean(predicted == y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48089887640449436"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = clf.predict(Bog_X_test)\n",
    "np.mean(predicted == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19127"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(clean_data)\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [clean_text(i) for i in newsgroups_train.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yang Li\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('clf', LogisticRegression(max_iter = 100))\n",
    " ])\n",
    "text_clf.fit(clean_data, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7631439192777483"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.74      0.66      0.70       319\n",
      "           comp.graphics       0.61      0.75      0.67       389\n",
      " comp.os.ms-windows.misc       0.65      0.67      0.66       394\n",
      "comp.sys.ibm.pc.hardware       0.65      0.65      0.65       392\n",
      "   comp.sys.mac.hardware       0.79      0.74      0.77       385\n",
      "          comp.windows.x       0.86      0.65      0.74       395\n",
      "            misc.forsale       0.73      0.89      0.81       390\n",
      "               rec.autos       0.87      0.76      0.81       396\n",
      "         rec.motorcycles       0.89      0.89      0.89       398\n",
      "      rec.sport.baseball       0.86      0.84      0.85       397\n",
      "        rec.sport.hockey       0.87      0.94      0.90       399\n",
      "               sci.crypt       0.88      0.85      0.86       396\n",
      "         sci.electronics       0.65      0.69      0.67       393\n",
      "                 sci.med       0.88      0.71      0.78       396\n",
      "               sci.space       0.84      0.87      0.86       394\n",
      "  soc.religion.christian       0.70      0.85      0.77       398\n",
      "      talk.politics.guns       0.67      0.82      0.74       364\n",
      "   talk.politics.mideast       0.89      0.79      0.84       376\n",
      "      talk.politics.misc       0.69      0.53      0.60       310\n",
      "      talk.religion.misc       0.57      0.56      0.56       251\n",
      "\n",
      "                accuracy                           0.76      7532\n",
      "               macro avg       0.76      0.76      0.76      7532\n",
      "            weighted avg       0.77      0.76      0.76      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 120548)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "text_clf1.fit(newsgroups_train.data, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274030801911842"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf1.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.74      0.77       319\n",
      "           comp.graphics       0.69      0.79      0.74       389\n",
      " comp.os.ms-windows.misc       0.75      0.73      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.83      0.74      0.78       395\n",
      "            misc.forsale       0.76      0.90      0.82       390\n",
      "               rec.autos       0.90      0.89      0.90       396\n",
      "         rec.motorcycles       0.95      0.95      0.95       398\n",
      "      rec.sport.baseball       0.88      0.92      0.90       397\n",
      "        rec.sport.hockey       0.94      0.95      0.95       399\n",
      "               sci.crypt       0.94      0.88      0.91       396\n",
      "         sci.electronics       0.76      0.80      0.78       393\n",
      "                 sci.med       0.89      0.83      0.85       396\n",
      "               sci.space       0.91      0.92      0.91       394\n",
      "  soc.religion.christian       0.81      0.94      0.87       398\n",
      "      talk.politics.guns       0.72      0.88      0.79       364\n",
      "   talk.politics.mideast       0.96      0.87      0.92       376\n",
      "      talk.politics.misc       0.76      0.59      0.66       310\n",
      "      talk.religion.misc       0.81      0.49      0.61       251\n",
      "\n",
      "                accuracy                           0.83      7532\n",
      "               macro avg       0.83      0.82      0.82      7532\n",
      "            weighted avg       0.83      0.83      0.83      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../data/test/AutoPhrase.txt' does not exist: b'../data/test/AutoPhrase.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-9af95025a003>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test/AutoPhrase.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'p'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'phrase'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mselect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m>=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../data/test/AutoPhrase.txt' does not exist: b'../data/test/AutoPhrase.txt'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/test/AutoPhrase.txt',error_bad_lines=False, delimiter= '\\t',names = ['p','phrase'])\n",
    "select = df[df.p >=0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_vect = ' '.join(select.phrase.apply(lambda x: str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1, 2))\n",
    "count_vect = count_vect.fit([text_for_vect])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count = count_vect.transform(news_df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 500).fit(X_count,newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7279607010090281"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = count_vect.transform(twenty_test.data)\n",
    "predicted = clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14379"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 14379)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_count)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 500).fit(X_train_tfidf,newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719065321295805"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = count_vect.transform(twenty_test.data)\n",
    "docs_test = tfidf_transformer.transform(docs_test)\n",
    "predicted = clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
