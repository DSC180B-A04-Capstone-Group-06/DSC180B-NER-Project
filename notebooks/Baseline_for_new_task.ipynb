{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import json\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns = ['text','type','summary','type_code']\n",
    "test_df = test_df.reset_index(drop = True)\n",
    "test_df.head()\n",
    "test_df.to_csv('../data/temp/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['business', 'entertainment', 'politics', 'sport', 'tech']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = \"../data/raw/BBC News Summary/News Articles/\"\n",
    "entries = os.listdir(data_folder)\n",
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "for i in entries:\n",
    "    temp = []\n",
    "    folder_path = data_folder + i +'/'\n",
    "    file_lst = os.listdir(folder_path)\n",
    "    for j in file_lst:\n",
    "        if j != '.ipynb_checkpoints':\n",
    "            with open(folder_path +j, 'r', errors='ignore') as file:\n",
    "                temp.append(file.read().replace('\\n', ''))\n",
    "    all_data[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_folder = \"../data/raw/BBC News Summary/Summaries/\"\n",
    "summary_entries = os.listdir(data_folder)\n",
    "all_sum = {}\n",
    "for i in entries:\n",
    "    temp = []\n",
    "    folder_path = summary_folder + i +'/'\n",
    "    file_lst = os.listdir(folder_path)\n",
    "    for j in file_lst:\n",
    "        if j != '.ipynb_checkpoints':\n",
    "            with open(folder_path +j, 'r', errors='ignore') as file:\n",
    "                temp.append(file.read().replace('\\n', ''))\n",
    "    all_sum[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for i in np.arange(len(entries)):\n",
    "    if i == 0:\n",
    "        total_df = pd.DataFrame.from_dict(all_data['business'])\n",
    "        total_df['type'] = 'business'\n",
    "        total_df['summary'] = all_sum['business']\n",
    "        total_df['type_code'] = i+1\n",
    "        \n",
    "        \n",
    "        index = np.random.choice(total_df.shape[0],10)\n",
    "        test_df = total_df.loc[index]\n",
    "    else:\n",
    "        temp_df = pd.DataFrame.from_dict(all_data[entries[i]])\n",
    "        temp_df['type'] = entries[i]\n",
    "        temp_df['summary'] = all_sum[entries[i]]\n",
    "        temp_df['type_code'] = i+1\n",
    "        total_df =pd.concat([total_df, temp_df], axis=0)\n",
    "        \n",
    "        index = np.random.choice(temp_df.shape[0], 10)\n",
    "        temp_test_df = temp_df.loc[index]\n",
    "        test_df =pd.concat([test_df,temp_test_df] , axis=0) \n",
    "        \n",
    "total_df.columns = ['text','type','summary','type_code']\n",
    "total_df = total_df.reset_index(drop = True)\n",
    "total_df.to_csv('../data/temp/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/raw/BBC News Summary/News Articles/\"\n",
    "entries = os.listdir('../data/raw/BBC News Summary/News Articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = \"../data/raw/BBC News Summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.DataFrame.from_dict(newsgroups_train,'index').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex_condi(string):\n",
    "    if \".com\" in string:\n",
    "        return False\n",
    "    if \".edu\" in string:\n",
    "        return False\n",
    "    if \"@\" in string:\n",
    "        return False\n",
    "    if 'Host'in string:\n",
    "        return False\n",
    "    if \".gov\" in string:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def clean_text(string):\n",
    "    string = \" \".join([i for i in string.split() if regex_condi(i)])\n",
    "    string = re.sub(r\"Re:\",\"\", string)\n",
    "    string = re.sub(r\"Reply-To:\",\"\", string)\n",
    "\n",
    "    string_lst = string.split(': ')\n",
    "    \n",
    "    \n",
    "    toreturn = \"\"\n",
    "    for i in np.arange(len(string_lst) - 1):\n",
    "        if \"Subject\" in string_lst[i]:\n",
    "            temp = string_lst[i+1].split(' ')\n",
    "            toreturn += \" \" + ' '.join(temp[:-1])\n",
    "        if \"Keywords\" in string_lst[i]:\n",
    "            temp = string_lst[i+1].split(' ')\n",
    "            toreturn += \" \" + ' '.join(temp[:-1])\n",
    "        if \"Organization\" in string_lst[i]:\n",
    "            temp = string_lst[i+1].split(' ')\n",
    "            toreturn += \" \" + ' '.join(temp[:-1])\n",
    "            \n",
    "        if \"Lines\" in string_lst[i]:\n",
    "            temp = \"\"\n",
    "            for j in range(i+1,len(string_lst)):\n",
    "                temp += string_lst[j]\n",
    "            toreturn += temp\n",
    "            break\n",
    "\n",
    "    toreturn = re.sub(r\"\\'\", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"\\>\", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"\\:\", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"^[0-9]+ \", \"\", toreturn)\n",
    "    toreturn = re.sub(r\"\\/\", ' ',toreturn)\n",
    "    toreturn = re.sub(r\"\\-{2,}\", ' ',toreturn)\n",
    "    toreturn = re.sub(r\"\\s+\", ' ',toreturn)\n",
    "    toreturn = toreturn.strip()\n",
    "    return toreturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('../data/temp',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/temp/text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(news_df.data.apply(lambda x: clean_text(x)+ '.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = ' '.join([f'{param}={value}' for param, value in json.load(open('../config/autophrase_cfg.json')).items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('git submodule init && git submodule update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'cd ../AutoPhrase/ && {para} ./auto_phrase.sh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.data = news_df.data.apply(lambda x: clean_text(x)+ '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/raw/20_newsgroups/\"\n",
    "entries = os.listdir(data_folder)\n",
    "all_data = {}\n",
    "for i in entries:\n",
    "    temp = []\n",
    "    folder_path = data_folder + i +'/'\n",
    "    file_lst = os.listdir(folder_path)\n",
    "    for j in file_lst:\n",
    "        if j != '.ipynb_checkpoints':\n",
    "            with open(folder_path +j, 'r', errors='ignore') as file:\n",
    "                temp.append(file.read().replace('\\n', ''))\n",
    "    all_data[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for i in np.arange(len(entries)):\n",
    "    if i == 0:\n",
    "        total_df = pd.DataFrame.from_dict(all_data['alt.atheism'])\n",
    "        total_df['type'] = 'alt.atheism'\n",
    "        total_df['type_code'] = i+1\n",
    "        \n",
    "        \n",
    "        index = np.random.choice(total_df.shape[0],10)\n",
    "        test_df = total_df.loc[index]\n",
    "    else:\n",
    "        temp_df = pd.DataFrame.from_dict(all_data[entries[i]])\n",
    "        temp_df['type'] = entries[i]\n",
    "        temp_df['type_code'] = i+1\n",
    "        total_df =pd.concat([total_df, temp_df], axis=0)\n",
    "        \n",
    "        index = np.random.choice(temp_df.shape[0], 10)\n",
    "        temp_test_df = temp_df.loc[index]\n",
    "        test_df =pd.concat([test_df,temp_test_df] , axis=0) \n",
    "        \n",
    "\n",
    "total_df = total_df.reset_index(drop = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv('../data/temp/all_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19127"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(clean_data)\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = [clean_text(i) for i in newsgroups_train.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('clf', LogisticRegression(max_iter = 100))\n",
    " ])\n",
    "text_clf.fit(clean_data, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7616834838024429"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = [clean_text(i) for i in twenty_test.data]\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.65      0.66      0.65       319\n",
      "           comp.graphics       0.67      0.73      0.70       389\n",
      " comp.os.ms-windows.misc       0.73      0.64      0.68       394\n",
      "comp.sys.ibm.pc.hardware       0.63      0.64      0.64       392\n",
      "   comp.sys.mac.hardware       0.76      0.77      0.77       385\n",
      "          comp.windows.x       0.81      0.71      0.76       395\n",
      "            misc.forsale       0.79      0.86      0.82       390\n",
      "               rec.autos       0.78      0.81      0.80       396\n",
      "         rec.motorcycles       0.85      0.90      0.87       398\n",
      "      rec.sport.baseball       0.82      0.88      0.85       397\n",
      "        rec.sport.hockey       0.91      0.90      0.91       399\n",
      "               sci.crypt       0.89      0.84      0.87       396\n",
      "         sci.electronics       0.66      0.69      0.67       393\n",
      "                 sci.med       0.81      0.77      0.79       396\n",
      "               sci.space       0.88      0.86      0.87       394\n",
      "  soc.religion.christian       0.72      0.81      0.76       398\n",
      "      talk.politics.guns       0.68      0.81      0.74       364\n",
      "   talk.politics.mideast       0.90      0.73      0.80       376\n",
      "      talk.politics.misc       0.64      0.52      0.58       310\n",
      "      talk.religion.misc       0.56      0.55      0.56       251\n",
      "\n",
      "                accuracy                           0.76      7532\n",
      "               macro avg       0.76      0.75      0.75      7532\n",
      "            weighted avg       0.76      0.76      0.76      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 120548)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression())])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', LogisticRegression()),\n",
    "])\n",
    "text_clf1.fit(newsgroups_train.data, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8274030801911842"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf1.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.74      0.77       319\n",
      "           comp.graphics       0.69      0.79      0.74       389\n",
      " comp.os.ms-windows.misc       0.75      0.73      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.72      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.83      0.74      0.78       395\n",
      "            misc.forsale       0.76      0.90      0.82       390\n",
      "               rec.autos       0.90      0.89      0.90       396\n",
      "         rec.motorcycles       0.95      0.95      0.95       398\n",
      "      rec.sport.baseball       0.88      0.92      0.90       397\n",
      "        rec.sport.hockey       0.94      0.95      0.95       399\n",
      "               sci.crypt       0.94      0.88      0.91       396\n",
      "         sci.electronics       0.76      0.80      0.78       393\n",
      "                 sci.med       0.89      0.83      0.85       396\n",
      "               sci.space       0.91      0.92      0.91       394\n",
      "  soc.religion.christian       0.81      0.94      0.87       398\n",
      "      talk.politics.guns       0.72      0.88      0.79       364\n",
      "   talk.politics.mideast       0.96      0.87      0.92       376\n",
      "      talk.politics.misc       0.76      0.59      0.66       310\n",
      "      talk.religion.misc       0.81      0.49      0.61       251\n",
      "\n",
      "                accuracy                           0.83      7532\n",
      "               macro avg       0.83      0.82      0.82      7532\n",
      "            weighted avg       0.83      0.83      0.83      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../model/20news/AutoPhrase.txt',error_bad_lines=False, delimiter= '\\t',names = ['p','phrase'])\n",
    "select = df[df.p >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_for_vect = ' '.join(select.phrase.apply(lambda x: str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8148"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(vocabulary=select.phrase ,stop_words = 'english')\n",
    "count_vect = count_vect.fit([text_for_vect])\n",
    "len(count_vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count = count_vect.transform(news_df.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter = 100).fit(X_count,newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.778146574614976"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = count_vect.transform(twenty_test.data)\n",
    "predicted = clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 8148)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_count)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter = 150).fit(X_train_tfidf,newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8100106213489113"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = count_vect.transform(twenty_test.data)\n",
    "docs_test = tfidf_transformer.transform(docs_test)\n",
    "predicted = clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.74      0.69      0.72       319\n",
      "           comp.graphics       0.71      0.78      0.74       389\n",
      " comp.os.ms-windows.misc       0.74      0.74      0.74       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.70      0.68       392\n",
      "   comp.sys.mac.hardware       0.80      0.77      0.78       385\n",
      "          comp.windows.x       0.81      0.74      0.77       395\n",
      "            misc.forsale       0.78      0.85      0.81       390\n",
      "               rec.autos       0.88      0.88      0.88       396\n",
      "         rec.motorcycles       0.90      0.93      0.92       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.93      0.96      0.95       399\n",
      "               sci.crypt       0.95      0.89      0.92       396\n",
      "         sci.electronics       0.70      0.73      0.71       393\n",
      "                 sci.med       0.87      0.85      0.86       396\n",
      "               sci.space       0.88      0.90      0.89       394\n",
      "  soc.religion.christian       0.78      0.91      0.84       398\n",
      "      talk.politics.guns       0.69      0.88      0.78       364\n",
      "   talk.politics.mideast       0.96      0.86      0.91       376\n",
      "      talk.politics.misc       0.76      0.56      0.64       310\n",
      "      talk.religion.misc       0.71      0.47      0.56       251\n",
      "\n",
      "                accuracy                           0.81      7532\n",
      "               macro avg       0.81      0.80      0.80      7532\n",
      "            weighted avg       0.81      0.81      0.81      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target, predicted,target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 58s, sys: 2h 59min 27s, total: 3h 19min 25s\n",
      "Wall time: 26min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = MLPClassifier(random_state=1, max_iter=100).fit(X_train_tfidf,newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8193043016463091"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "docs_test = count_vect.transform(twenty_test.data)\n",
    "docs_test = tfidf_transformer.transform(docs_test)\n",
    "predicted = clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
